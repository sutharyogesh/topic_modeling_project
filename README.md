# Document Clustering and Topic Modeling Project

A comprehensive Python implementation for document clustering and topic modeling using the 20 Newsgroups dataset. This project applies both K-means clustering and Latent Dirichlet Allocation (LDA) to analyze text documents and discover underlying patterns.

## ğŸ¯ Project Overview

This project provides a complete pipeline for:
- **Document Clustering** using K-means algorithm
- **Topic Modeling** using Latent Dirichlet Allocation (LDA)
- **Text Preprocessing** with advanced NLP techniques
- **Interactive Visualizations** for results exploration
- **Model Evaluation** with comprehensive metrics
- **Web Dashboard** for easy interaction

## ğŸš€ Features

### Core Functionality
- âœ… **K-means Clustering** with TF-IDF vectorization
- âœ… **LDA Topic Modeling** with Bag-of-Words representation
- âœ… **Advanced Text Preprocessing** (tokenization, lemmatization, stop-word removal)
- âœ… **Multiple Evaluation Metrics** (Silhouette Score, Coherence Score, Perplexity)
- âœ… **Dimensionality Reduction** (PCA, t-SNE) for visualization
- âœ… **Interactive Visualizations** (pyLDAvis, Plotly charts)

### Web Interfaces
- ğŸŒ **Streamlit Dashboard** - Interactive data science interface
- ğŸŒ **Flask Web App** - Professional web application
- ğŸ“Š **Real-time Analysis** with dynamic parameter adjustment
- ğŸ“ **Custom Dataset Upload** support

### Visualizations
- ğŸ“ˆ **t-SNE Cluster Plots** - 2D visualization of document clusters
- ğŸ“Š **Topic Distribution Charts** - Interactive topic analysis
- â˜ï¸ **Word Clouds** - Visual representation of topic keywords
- ğŸ“‰ **Performance Metrics** - Model evaluation dashboards
- ğŸ¯ **Model Comparison** - Side-by-side algorithm comparison

## ğŸ“‹ Requirements

### Python Packages
```
scikit-learn==1.3.0
gensim==4.3.2
spacy==3.7.2
nltk==3.8.1
pandas==2.0.3
numpy==1.24.3
matplotlib==3.7.2
seaborn==0.12.2
plotly==5.15.0
wordcloud==1.9.2
pyLDAvis==3.4.1
streamlit==1.25.0
flask==2.3.2
```

### Additional Setup
- spaCy English model: `python -m spacy download en_core_web_sm`
- NLTK data packages (downloaded automatically)

## ğŸ› ï¸ Installation

1. **Clone the repository:**
```bash
git clone <repository-url>
cd document-clustering-topic-modeling
```

2. **Install dependencies:**
```bash
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```

3. **Run the application:**

**Option A: Streamlit Dashboard**
```bash
python run_streamlit.py
```

**Option B: Flask Web App**
```bash
python run_flask.py
```

**Option C: Command Line Interface**
```bash
python main.py
```


## ğŸ¥ Demo

![Demo](demo/demo.mp4)

## ğŸ“– Usage

### 1. Streamlit Dashboard
- Navigate to `http://localhost:8501`
- Upload custom datasets or use 20 Newsgroups
- Adjust parameters with interactive sliders
- View real-time analysis results

### 2. Flask Web Application
- Navigate to `http://localhost:5000`
- Professional web interface
- Upload and analyze custom datasets
- Download analysis reports

### 3. Python API
```python
from main import DocumentAnalysisPipeline

# Initialize pipeline
pipeline = DocumentAnalysisPipeline(n_clusters=8, n_topics=8)

# Run complete analysis
results = pipeline.run_full_pipeline()

# Access results
print(f"Silhouette Score: {results['silhouette_score']:.3f}")
print(f"Coherence Score: {results['coherence_score']:.3f}")
```


### 20 Newsgroups Dataset
- **Documents**: ~18,000 newsgroup posts
- **Categories**: 20 different topics
- **Typical Performance**:
  - Silhouette Score: 0.15-0.35
  - Coherence Score: 0.45-0.65
  - Processing Time: 2-5 minutes

### Performance Benchmarks
| Dataset Size | Preprocessing | Clustering | Topic Modeling | Total Time |
|-------------|---------------|------------|----------------|------------|
| 1,000 docs  | 30s          | 5s         | 45s           | ~1.5 min   |
| 5,000 docs  | 2 min        | 15s        | 3 min         | ~5.5 min   |
| 18,000 docs | 6 min        | 45s        | 8 min         | ~15 min    |


## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
